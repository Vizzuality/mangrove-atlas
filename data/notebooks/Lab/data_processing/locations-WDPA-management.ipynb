{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6c9a24",
   "metadata": {},
   "source": [
    "# WDPA management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883516a8",
   "metadata": {},
   "source": [
    "create_mangrove_wdpa_table.js file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60246a68",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import geopandas\n",
    "import zipfile\n",
    "import subprocess\n",
    "import logging\n",
    "import requests\n",
    "from typing import Union\n",
    "from ipyleaflet import Map, GeoData, basemaps, LayersControl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa4f76ee",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[?25h              \u001b[27m] - reify:@tmcw/togeojson: \u001b[32;40mhttp\u001b[0m \u001b[35mfetch\u001b[0m GET 200 https://regist\u001b[0m\u001b[K.o\u001b[0m\u001b[K\n",
      "added 67 packages, and audited 68 packages in 7s\n",
      "\n",
      "6 packages are looking for funding\n",
      "  run `npm fund` for details\n",
      "\n",
      "found \u001b[32m\u001b[1m0\u001b[22m\u001b[39m vulnerabilities\n"
     ]
    }
   ],
   "source": [
    "!npm install -g mapshaper@latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2ac5fb1",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#  FIXME: This will depends from where the notebook kernel is running so be careful\n",
    "WORK_DIR =Path(os.getcwd())\n",
    "BASE_DIR = f'{WORK_DIR.parents[3]}/work/datasets/raw'\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# @TODO: Add expected data files source as an environment variable.\n",
    "assert BASE_DIR == '/home/jovyan/work/datasets/raw', f'{BASE_DIR} is not the correct directory'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8477cc",
   "metadata": {},
   "source": [
    "## Pipeline for wdpa download and simplification process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56557904",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e5baf5b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def download_wdpaData(file_path: str, update: bool = False) -> Union[int, str]:\n",
    "    \"\"\"\n",
    "    Download a WDPA file to a path.\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str - The path to the file to download.\n",
    "    update : bool, optional - If True, the file will be downloaded again even if it already exists.\n",
    "                            The default is False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int - 0 if the file was downloaded successfully, 1 if the file download failed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if update or not os.path.exists(file_path):\n",
    "            logging.info('Downloading WDPA data...')\n",
    "            \n",
    "            url_info = requests.post('https://www.protectedplanet.net/downloads',\n",
    "                                data={\"domain\":\"general\",\n",
    "                                    \"format\":\"shp\",\n",
    "                                    \"token\":\"wdpa\",\n",
    "                                    \"id\":51216}\n",
    "                                )\n",
    "            \n",
    "            response = requests.get(url_info.json()['url'], stream=True)\n",
    "        \n",
    "            with open(file_path, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=128):\n",
    "                    f.write(chunk)\n",
    "        else:\n",
    "            logging.info('WDPA data already downloaded.')    \n",
    "        \n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "509c56c7",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def extract_wdpa_data(wdpa_zip_file: str, target_folder: str, format: str='.zip', update: bool = False) -> int:\n",
    "\n",
    "    \"\"\"\n",
    "    Extract WDPA data from a zip file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    wdpa_zip_file : str - The path to the zip file containing the WDPA data.\n",
    "    target_folder : str - The path to the folder to extract the WDPA data to.\n",
    "    format : str, optional - The format of the zip file. The default is '.zip'.\n",
    "    update : bool, optional - If True, the file will be extracted even if it already exists.\n",
    "                            The default is False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int - 0 if the file was extracted successfully, 1 if the file extraction failed.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        path = f'{BASE_DIR}/{target_folder}'\n",
    "\n",
    "        if update or not os.path.exists(path):\n",
    "            logging.info('Extracting WDPA data...')\n",
    "               \n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "\n",
    "            with zipfile.ZipFile(wdpa_zip_file, 'r') as zip_ref:\n",
    "                sublist = filter(lambda file: format in file, zip_ref.namelist())\n",
    "                zip_ref.extractall(path, members=sublist)\n",
    "        \n",
    "            for file in os.listdir(path):\n",
    "                if file.endswith(format):\n",
    "                    logging.info(file)\n",
    "                    \n",
    "                    inner_folder = f'{path}/{file[:-len(format)]}'\n",
    "                    \n",
    "                    with zipfile.ZipFile(f'{path}/{file}', 'r') as zip_ref:\n",
    "                        if not os.path.exists(inner_folder):\n",
    "                            os.mkdir(inner_folder)\n",
    "\n",
    "                        zip_ref.extractall(inner_folder)\n",
    "                    \n",
    "                    os.remove(f'{path}/{file}')\n",
    "        else:\n",
    "            logging.info('WDPA data already extracted.')\n",
    "            \n",
    "        return 0\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f3b816",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataframe(file_path: str) -> Union[int, geopandas.GeoDataFrame]:\n",
    "    \"\"\"\n",
    "    Load WDPA data from a csv file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str - The path to the csv file to load.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geopandas.GeoDataFrame - The loaded data.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return geopandas.read_file(file_path)\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c91f749",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def simplifyMapshaper(data_path: Path, output_path: Path, \n",
    "    simplification: bool, clip: bool = False, update: bool = False) -> Union[int, Path]:\n",
    "    \"\"\"\n",
    "    Simplify geometry of a GeoDataFrame using mapshaper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_path : Path - The path to the GeoDataFrame to simplify.\n",
    "    output_path : Path - The path to the output GeoDataFrame.\n",
    "    simplification : bool - If True, the data will be simplified.\n",
    "    update : bool, optional - If True, the output GeoDataFrame will be overwritten.\n",
    "                            The default is False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int - 0 if the data was simplified successfully, 1 if the data simplification failed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        if update or not output_path.exists:\n",
    "            logging.info('Filtering WDPA data based on Ramsar designation and in active protection...')\n",
    "            instructions = []\n",
    "            instructions.append(f\"mapshaper-xl 16gb -i {data_path} combine-files snap\")\n",
    "            instructions.append(f\"-o {output_path} format=shapefile force\")\n",
    "            instructions.insert(1,\"-filter \\'STATUS!=\\\"Proposed\\\"\\'\")\n",
    "            instructions.insert(2,\"-filter \\'\\\"ABW,AGO,AIA,ARE,ASM,ATG,AUS,BEN,BES,BGD,BHR,BHS,BLZ,BRA,BRB,BRN,CHN,CIV,CMR,COD,COL,COM,CRI,CUB,CUW,CYM,DJI,DMA,DOM,DPT,ECU,EGY,ERI,FJI,FSM,GAB,GHA,GIN,GLP,GMB,GNB,GNQ,GRD,GTM,GUF,GUY,HKG,HND,HTI,IDN,IND,IRN,JAM,JPN,KEN,KHM,KNA,LBR,LCA,LKA,MAF,MDG,MEX,MMR,MOZ,MRT,MTQ,MUS,MYS,MYT,NCL,NGA,NIC,NZL,OMN,PAK,PAN,PER,PHL,PLW,PNG,PRI,QAT,SAU,SDN,SEN,SGP,SLB,SLE,SLV,SOM,STP,SUR,SYC,TCA,THA,TLS,TON,TTO,TWN,TZA,USA,VCT,VEN,VGB,VIR,VNM,VUT,WSM,YEM,ZAF\\\".indexOf(ISO3) > -1\\'\")\n",
    "            instructions.insert(3,\"-filter bbox=-180,-50,180,50 remove-empty\")\n",
    "            instructions.insert(4,\"-merge-layers target=*\")\n",
    "            instructions.insert(5,\"-clean allow-overlaps\")\n",
    "            if clip:\n",
    "                instructions.insert(6, \"-clip source={BASE_DIR}/mangrove_coverage-v2.shp target=*\")\n",
    "\n",
    "            CMD = ' '.join(instructions)\n",
    "            print(CMD)\n",
    "            subprocess.run(CMD, shell=True, check=True)\n",
    "        \n",
    "        if simplification:\n",
    "            logging.info('Simplifying WDPA data...')\n",
    "            CMD2 = f\"mapshaper-xl 16gb -i {output_path} \\\n",
    "                -simplify 50% visvalingam keep-shapes planar \\\n",
    "                -filter-islands min-vertices=3 min-area=10000m2 remove-empty \\\n",
    "                -filter-slivers min-area=10000m2 remove-empty \\\n",
    "                -clean rewind \\\n",
    "                -o {output_path} format=shapefile force\"\n",
    "            subprocess.run(CMD2, shell=True, check=True)\n",
    "        \n",
    "        return output_path\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb6ef04",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def mapRender(data: geopandas.GeoDataFrame) -> Map:\n",
    "    \"\"\"\n",
    "    Render a map with the given data.\n",
    "    Parameters-f\n",
    "    ----------\n",
    "    data : geopandas.GeoDataFrame - The data to render.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Map - The rendered map.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        m = Map(center=(52.3,8.0), \n",
    "            zoom = 3, \n",
    "            basemap= basemaps.Esri.WorldTopoMap,\n",
    "            layers_control=True,\n",
    "            controls=[\n",
    "                LayersControl()\n",
    "            ])\n",
    "        geo_data = GeoData(\n",
    "                    geo_dataframe=data,\n",
    "                    style={\n",
    "                        'color': '#ff0000',\n",
    "                        'fillOpacity': 0.5\n",
    "                    },\n",
    "                    name='WDPA',\n",
    "                )\n",
    "        m.add_layer(geo_data)\n",
    "\n",
    "        \n",
    "        return m\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0a99ab",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7b1f43d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:WDPA data already downloaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_wdpaData(f'{BASE_DIR}/wdpa_protected_areas_public.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2229eb24",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:WDPA data already extracted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_wdpa_data(f'{BASE_DIR}/wdpa_protected_areas_public.zip', 'wdpa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa6b7985",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/datasets/processed/wdpa_protected_areas_public.shp\n"
     ]
    }
   ],
   "source": [
    "outFolder= Path(f'{BASE_DIR}/wdpa')\n",
    "paths =[]\n",
    "for root, dirs, files in os.walk(outFolder):\n",
    "    for file in files:\n",
    "        if file.endswith(\"-polygons.shp\"):\n",
    "            paths.append(os.path.join(root, file))\n",
    "\n",
    "path = ' '.join(paths)\n",
    "\n",
    "outputPath = f'{outFolder.parents[1]}/processed/wdpa_protected_areas_public.shp'\n",
    "\n",
    "print(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e14d4bc5",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering WDPA data based on Ramsar designation and in active protection...\n",
      "Allocating 16 GB of heap memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapshaper-xl 16gb -i /home/jovyan/work/datasets/raw/wdpa/WDPA_Feb2022_Public_shp_1/WDPA_Feb2022_Public_shp-polygons.shp /home/jovyan/work/datasets/raw/wdpa/WDPA_Feb2022_Public_shp_2/WDPA_Feb2022_Public_shp-polygons.shp /home/jovyan/work/datasets/raw/wdpa/WDPA_Feb2022_Public_shp_0/WDPA_Feb2022_Public_shp-polygons.shp combine-files snap -filter 'STATUS!=\"Proposed\"' -filter '\"ABW,AGO,AIA,ARE,ASM,ATG,AUS,BEN,BES,BGD,BHR,BHS,BLZ,BRA,BRB,BRN,CHN,CIV,CMR,COD,COL,COM,CRI,CUB,CUW,CYM,DJI,DMA,DOM,DPT,ECU,EGY,ERI,FJI,FSM,GAB,GHA,GIN,GLP,GMB,GNB,GNQ,GRD,GTM,GUF,GUY,HKG,HND,HTI,IDN,IND,IRN,JAM,JPN,KEN,KHM,KNA,LBR,LCA,LKA,MAF,MDG,MEX,MMR,MOZ,MRT,MTQ,MUS,MYS,MYT,NCL,NGA,NIC,NZL,OMN,PAK,PAN,PER,PHL,PLW,PNG,PRI,QAT,SAU,SDN,SEN,SGP,SLB,SLE,SLV,SOM,STP,SUR,SYC,TCA,THA,TLS,TON,TTO,TWN,TZA,USA,VCT,VEN,VGB,VIR,VNM,VUT,WSM,YEM,ZAF\".indexOf(ISO3) > -1' -filter bbox=-180,-50,180,50 remove-empty -merge-layers target=* -clean allow-overlaps -o /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.shp format=shapefile force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[i] Snapped 19910585 points\n",
      "[filter] Retained 85,479 of 85,785 features\n",
      "[filter] Retained 85,513 of 85,784 features\n",
      "[filter] Retained 85,140 of 85,785 features\n",
      "[filter] Retained 24,213 of 85,479 features\n",
      "[filter] Retained 40,419 of 85,513 features\n",
      "[filter] Retained 22,048 of 85,140 features\n",
      "[filter] Retained 24,159 of 24,213 features\n",
      "[filter] Retained 40,256 of 40,419 features\n",
      "[filter] Retained 21,940 of 22,048 features\n",
      "[clean] Retained 86,355 of 86,355 features\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.shp\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.shx\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.dbf\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.prj\n",
      "INFO:root:Simplifying WDPA data...\n",
      "Allocating 16 GB of heap memory\n",
      "[simplify] Repaired 11,081 intersections; 2,395 intersections could not be repaired\n",
      "[filter-islands] Detected DBF text encoding: utf8\n",
      "[filter-islands] Removed 177,362 islands\n",
      "[filter-slivers] Removed 85,505 slivers using 0.01+ sqkm variable threshold\n",
      "[clean] Removed 82,795 / 107,661 slivers using 7200+ sqm variable threshold\n",
      "[clean] Retained 72,372 of 82,387 features\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.shp\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.shx\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.dbf\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.prj\n"
     ]
    }
   ],
   "source": [
    "wdpa = simplifyMapshaper(path, outputPath, simplification=True, update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d8692c7",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "wdpa_dataframe = load_dataframe(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40acc5f9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "extent_dataframe = load_dataframe(Path(f'{BASE_DIR}/coastlines-mangroves-v1.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63a894f0",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 72372 entries, 0 to 72371\n",
      "Data columns (total 31 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   WDPAID      72372 non-null  int64   \n",
      " 1   WDPA_PID    72372 non-null  object  \n",
      " 2   PA_DEF      72372 non-null  object  \n",
      " 3   NAME        72372 non-null  object  \n",
      " 4   ORIG_NAME   72372 non-null  object  \n",
      " 5   DESIG       72372 non-null  object  \n",
      " 6   DESIG_ENG   72372 non-null  object  \n",
      " 7   DESIG_TYPE  72372 non-null  object  \n",
      " 8   IUCN_CAT    72372 non-null  object  \n",
      " 9   INT_CRIT    72372 non-null  object  \n",
      " 10  MARINE      72372 non-null  object  \n",
      " 11  REP_M_AREA  72372 non-null  float64 \n",
      " 12  GIS_M_AREA  72372 non-null  float64 \n",
      " 13  REP_AREA    72372 non-null  float64 \n",
      " 14  GIS_AREA    72372 non-null  float64 \n",
      " 15  NO_TAKE     72372 non-null  object  \n",
      " 16  NO_TK_AREA  72372 non-null  float64 \n",
      " 17  STATUS      72372 non-null  object  \n",
      " 18  STATUS_YR   72372 non-null  int64   \n",
      " 19  GOV_TYPE    72372 non-null  object  \n",
      " 20  OWN_TYPE    72372 non-null  object  \n",
      " 21  MANG_AUTH   72372 non-null  object  \n",
      " 22  MANG_PLAN   72372 non-null  object  \n",
      " 23  VERIF       72372 non-null  object  \n",
      " 24  METADATAID  72372 non-null  int64   \n",
      " 25  SUB_LOC     72372 non-null  object  \n",
      " 26  PARENT_ISO  72372 non-null  object  \n",
      " 27  ISO3        72372 non-null  object  \n",
      " 28  SUPP_INFO   72372 non-null  object  \n",
      " 29  CONS_OBJ    72372 non-null  object  \n",
      " 30  geometry    72372 non-null  geometry\n",
      "dtypes: float64(5), geometry(1), int64(3), object(22)\n",
      "memory usage: 17.1+ MB\n"
     ]
    }
   ],
   "source": [
    "wdpa_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81b4365b",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "Filtered = wdpa_dataframe.sjoin(extent_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7fa03b6",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123/3948432504.py:2: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  Filtered.to_file(f'{outFolder.parents[1]}/processed/wdpa_protected_areas_public_filtered.shp')\n",
      "WARNING:fiona._env:Normalized/laundered field name: 'index_right' to 'index_righ'\n"
     ]
    }
   ],
   "source": [
    "Filtered.dropna(inplace=True)\n",
    "Filtered.to_file(f'{outFolder.parents[1]}/processed/wdpa_protected_areas_public_filtered.shp') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48158b14",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: add a function to zip data and upload it to google cloud storage bucket\n",
    "# TODO: we are not intersecting here by the actual mangrove extent data. So we are getting more WDPA that the ones that are actually protecting mangroves."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "key": "interpreter",
     "op": "add",
     "value": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
     }
    },
    {
     "diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 4,
           "op": "addrange",
           "valuelist": "6"
          },
          {
           "key": 4,
           "length": 2,
           "op": "removerange"
          }
         ],
         "key": 0,
         "op": "patch"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "key": "interpreter",
     "op": "add",
     "value": {
      "hash": "1bbcc470f389489f4ea214123e5e87adfd3a5448567a8d2709d702e835c91736"
     }
    },
    {
     "key": "language_info",
     "op": "remove"
    }
   ]
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
