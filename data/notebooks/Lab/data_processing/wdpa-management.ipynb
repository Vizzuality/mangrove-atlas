{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6c9a24",
   "metadata": {},
   "source": [
    "# WDPA management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883516a8",
   "metadata": {},
   "source": [
    "create_mangrove_wdpa_table.js file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60246a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import geopandas\n",
    "import zipfile\n",
    "import subprocess\n",
    "import logging\n",
    "import requests\n",
    "from typing import Union\n",
    "from ipyleaflet import Map, GeoData, basemaps, LayersControl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa4f76ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[?25h              \u001b[27m] - reify:mproj: \u001b[32;40mtiming\u001b[0m \u001b[35mreifyNode:node_modules/mapshaper/nod\u001b[0m\u001b[K0ms\u001b[0m\u001b[K\n",
      "changed 67 packages, and audited 68 packages in 4s\n",
      "\n",
      "6 packages are looking for funding\n",
      "  run `npm fund` for details\n",
      "\n",
      "found \u001b[32m\u001b[1m0\u001b[22m\u001b[39m vulnerabilities\n"
     ]
    }
   ],
   "source": [
    "!npm install -g mapshaper@latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2ac5fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  FIXME: This will depends from where the notebook kernel is running so be careful\n",
    "WORK_DIR =Path(os.getcwd())\n",
    "BASE_DIR = f'{WORK_DIR.parents[3]}/work/datasets/raw'\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# @TODO: Add expected data files source as an environment variable.\n",
    "assert BASE_DIR == '/home/jovyan/work/datasets/raw', f'{BASE_DIR} is not the correct directory'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8477cc",
   "metadata": {},
   "source": [
    "## Pipeline for wdpa download and simplification process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56557904",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e5baf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_wdpaData(file_path: str, update: bool = False) -> Union[int, str]:\n",
    "    \"\"\"\n",
    "    Download a WDPA file to a path.\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str - The path to the file to download.\n",
    "    update : bool, optional - If True, the file will be downloaded again even if it already exists.\n",
    "                            The default is False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int - 0 if the file was downloaded successfully, 1 if the file download failed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if update or not os.path.exists(file_path):\n",
    "            logging.info('Downloading WDPA data...')\n",
    "            \n",
    "            url_info = requests.post('https://www.protectedplanet.net/downloads',\n",
    "                                data={\"domain\":\"general\",\n",
    "                                    \"format\":\"shp\",\n",
    "                                    \"token\":\"wdpa\",\n",
    "                                    \"id\":51216}\n",
    "                                )\n",
    "            \n",
    "            response = requests.get(url_info.json()['url'], stream=True)\n",
    "        \n",
    "            with open(file_path, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=128):\n",
    "                    f.write(chunk)\n",
    "        else:\n",
    "            logging.info('WDPA data already downloaded.')    \n",
    "        \n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "509c56c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wdpa_data(wdpa_zip_file: str, target_folder: str, format: str='.zip', update: bool = False) -> int:\n",
    "\n",
    "    \"\"\"\n",
    "    Extract WDPA data from a zip file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    wdpa_zip_file : str - The path to the zip file containing the WDPA data.\n",
    "    target_folder : str - The path to the folder to extract the WDPA data to.\n",
    "    format : str, optional - The format of the zip file. The default is '.zip'.\n",
    "    update : bool, optional - If True, the file will be extracted even if it already exists.\n",
    "                            The default is False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int - 0 if the file was extracted successfully, 1 if the file extraction failed.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        path = f'{BASE_DIR}/{target_folder}'\n",
    "\n",
    "        if update or not os.path.exists(path):\n",
    "            logging.info('Extracting WDPA data...')\n",
    "               \n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "\n",
    "            with zipfile.ZipFile(wdpa_zip_file, 'r') as zip_ref:\n",
    "                sublist = filter(lambda file: format in file, zip_ref.namelist())\n",
    "                zip_ref.extractall(path, members=sublist)\n",
    "        \n",
    "            for file in os.listdir(path):\n",
    "                if file.endswith(format):\n",
    "                    logging.info(file)\n",
    "                    \n",
    "                    inner_folder = f'{path}/{file[:-len(format)]}'\n",
    "                    \n",
    "                    with zipfile.ZipFile(f'{path}/{file}', 'r') as zip_ref:\n",
    "                        if not os.path.exists(inner_folder):\n",
    "                            os.mkdir(inner_folder)\n",
    "\n",
    "                        zip_ref.extractall(inner_folder)\n",
    "                    \n",
    "                    os.remove(f'{path}/{file}')\n",
    "        else:\n",
    "            logging.info('WDPA data already extracted.')\n",
    "            \n",
    "        return 0\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59f3b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wdpa_data(file_path: str) -> Union[int, geopandas.GeoDataFrame]:\n",
    "    \"\"\"\n",
    "    Load WDPA data from a csv file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str - The path to the csv file to load.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geopandas.GeoDataFrame - The loaded data.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return geopandas.read_file(file_path)\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9c91f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplifyMapshaper(data_path: Path, output_path: Path, \n",
    "    simplification: bool, clip: bool = False, update: bool = False) -> Union[int, Path]:\n",
    "    \"\"\"\n",
    "    Simplify geometry of a GeoDataFrame using mapshaper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_path : Path - The path to the GeoDataFrame to simplify.\n",
    "    output_path : Path - The path to the output GeoDataFrame.\n",
    "    simplification : bool - If True, the data will be simplified.\n",
    "    update : bool, optional - If True, the output GeoDataFrame will be overwritten.\n",
    "                            The default is False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int - 0 if the data was simplified successfully, 1 if the data simplification failed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        if update or not output_path.exists:\n",
    "            logging.info('Filtering WDPA data based on Ramsar designation and in active protection...')\n",
    "            instructions = []\n",
    "            instructions.append(f\"mapshaper-xl 16gb -i {data_path} combine-files snap\")\n",
    "            instructions.append(f\"-o {output_path} format=shapefile force\")\n",
    "            instructions.insert(1,\"-filter \\'STATUS!=\\\"Proposed\\\"\\'\")\n",
    "            instructions.insert(2,\"-filter \\'\\\"ABW,AGO,AIA,ARE,ASM,ATG,AUS,BEN,BES,BGD,BHR,BHS,BLZ,BRA,BRB,BRN,CHN,CIV,CMR,COD,COL,COM,CRI,CUB,CUW,CYM,DJI,DMA,DOM,DPT,ECU,EGY,ERI,FJI,FSM,GAB,GHA,GIN,GLP,GMB,GNB,GNQ,GRD,GTM,GUF,GUY,HKG,HND,HTI,IDN,IND,IRN,JAM,JPN,KEN,KHM,KNA,LBR,LCA,LKA,MAF,MDG,MEX,MMR,MOZ,MRT,MTQ,MUS,MYS,MYT,NCL,NGA,NIC,NZL,OMN,PAK,PAN,PER,PHL,PLW,PNG,PRI,QAT,SAU,SDN,SEN,SGP,SLB,SLE,SLV,SOM,STP,SUR,SYC,TCA,THA,TLS,TON,TTO,TWN,TZA,USA,VCT,VEN,VGB,VIR,VNM,VUT,WSM,YEM,ZAF\\\".indexOf(ISO3) > -1\\'\")\n",
    "            instructions.insert(3,\"-filter bbox=-180,-50,180,50 remove-empty\")\n",
    "            instructions.insert(4,\"-merge-layers target=*\")\n",
    "            instructions.insert(5,\"-clean allow-overlaps\")\n",
    "            if clip:\n",
    "                instructions.insert(6, \"-clip source={BASE_DIR}/mangrove_coverage-v2.shp target=*\")\n",
    "\n",
    "            CMD = ' '.join(instructions)\n",
    "            print(CMD)\n",
    "            subprocess.run(CMD, shell=True, check=True)\n",
    "        \n",
    "        if simplification:\n",
    "            logging.info('Simplifying WDPA data...')\n",
    "            CMD2 = f\"mapshaper-xl 16gb -i {output_path} \\\n",
    "                -simplify 50% visvalingam keep-shapes planar \\\n",
    "                -filter-islands min-vertices=3 min-area=10000m2 remove-empty \\\n",
    "                -filter-slivers min-area=10000m2 remove-empty \\\n",
    "                -clean rewind \\\n",
    "                -o {output_path} format=shapefile force\"\n",
    "            subprocess.run(CMD2, shell=True, check=True)\n",
    "        \n",
    "        return output_path\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcb6ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapRender(data: geopandas.GeoDataFrame) -> Map:\n",
    "    \"\"\"\n",
    "    Render a map with the given data.\n",
    "    Parameters-f\n",
    "    ----------\n",
    "    data : geopandas.GeoDataFrame - The data to render.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Map - The rendered map.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        m = Map(center=(52.3,8.0), \n",
    "            zoom = 3, \n",
    "            basemap= basemaps.Esri.WorldTopoMap,\n",
    "            layers_control=True,\n",
    "            controls=[\n",
    "                LayersControl()\n",
    "            ])\n",
    "        geo_data = GeoData(\n",
    "                    geo_dataframe=data,\n",
    "                    style={\n",
    "                        'color': '#ff0000',\n",
    "                        'fillOpacity': 0.5\n",
    "                    },\n",
    "                    name='WDPA',\n",
    "                )\n",
    "        m.add_layer(geo_data)\n",
    "\n",
    "        \n",
    "        return m\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0a99ab",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7b1f43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:WDPA data already downloaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_wdpaData(f'{BASE_DIR}/wdpa_protected_areas_public.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2229eb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:WDPA data already extracted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_wdpa_data(f'{BASE_DIR}/wdpa_protected_areas_public.zip', 'wdpa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa6b7985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/datasets/processed/wdpa_protected_areas_public.shp\n"
     ]
    }
   ],
   "source": [
    "outFolder= Path(f'{BASE_DIR}/wdpa')\n",
    "paths =[]\n",
    "for root, dirs, files in os.walk(outFolder):\n",
    "    for file in files:\n",
    "        if file.endswith(\"-polygons.shp\"):\n",
    "            paths.append(os.path.join(root, file))\n",
    "\n",
    "path = ' '.join(paths)\n",
    "\n",
    "outputPath = f'{outFolder.parents[1]}/processed/wdpa_protected_areas_public.shp'\n",
    "\n",
    "print(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e14d4bc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering WDPA data based on Ramsar designation and in active protection...\n",
      "Allocating 16 GB of heap memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapshaper-xl 16gb -i /home/jovyan/work/datasets/raw/wdpa/WDPA_Feb2022_Public_shp_1/WDPA_Feb2022_Public_shp-polygons.shp /home/jovyan/work/datasets/raw/wdpa/WDPA_Feb2022_Public_shp_2/WDPA_Feb2022_Public_shp-polygons.shp /home/jovyan/work/datasets/raw/wdpa/WDPA_Feb2022_Public_shp_0/WDPA_Feb2022_Public_shp-polygons.shp combine-files snap -filter 'STATUS!=\"Proposed\"' -filter '\"ABW,AGO,AIA,ARE,ASM,ATG,AUS,BEN,BES,BGD,BHR,BHS,BLZ,BRA,BRB,BRN,CHN,CIV,CMR,COD,COL,COM,CRI,CUB,CUW,CYM,DJI,DMA,DOM,DPT,ECU,EGY,ERI,FJI,FSM,GAB,GHA,GIN,GLP,GMB,GNB,GNQ,GRD,GTM,GUF,GUY,HKG,HND,HTI,IDN,IND,IRN,JAM,JPN,KEN,KHM,KNA,LBR,LCA,LKA,MAF,MDG,MEX,MMR,MOZ,MRT,MTQ,MUS,MYS,MYT,NCL,NGA,NIC,NZL,OMN,PAK,PAN,PER,PHL,PLW,PNG,PRI,QAT,SAU,SDN,SEN,SGP,SLB,SLE,SLV,SOM,STP,SUR,SYC,TCA,THA,TLS,TON,TTO,TWN,TZA,USA,VCT,VEN,VGB,VIR,VNM,VUT,WSM,YEM,ZAF\".indexOf(ISO3) > -1' -filter bbox=-180,-50,180,50 remove-empty -merge-layers target=* -clean allow-overlaps -o /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.shp format=shapefile force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[i] Snapped 19910585 points\n",
      "[filter] Retained 85,479 of 85,785 features\n",
      "[filter] Retained 85,513 of 85,784 features\n",
      "[filter] Retained 85,140 of 85,785 features\n",
      "[filter] Retained 24,213 of 85,479 features\n",
      "[filter] Retained 40,419 of 85,513 features\n",
      "[filter] Retained 22,048 of 85,140 features\n",
      "[filter] Retained 24,159 of 24,213 features\n",
      "[filter] Retained 40,256 of 40,419 features\n",
      "[filter] Retained 21,940 of 22,048 features\n",
      "[clean] Retained 86,355 of 86,355 features\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.shp\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.shx\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.dbf\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.prj\n",
      "INFO:root:Simplifying WDPA data...\n",
      "Allocating 16 GB of heap memory\n",
      "[simplify] Repaired 11,081 intersections; 2,395 intersections could not be repaired\n",
      "[filter-islands] Detected DBF text encoding: utf8\n",
      "[filter-islands] Removed 177,362 islands\n",
      "[filter-slivers] Removed 85,505 slivers using 0.01+ sqkm variable threshold\n",
      "[clean] Removed 82,795 / 107,661 slivers using 7200+ sqm variable threshold\n",
      "[clean] Retained 72,372 of 82,387 features\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.shp\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.shx\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.dbf\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.prj\n"
     ]
    }
   ],
   "source": [
    "wdpa = simplifyMapshaper(path, outputPath, simplification=True, update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd29bc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering WDPA data based on Ramsar designation and in active protection...\n",
      "Allocating 16 GB of heap memory\n",
      "[i] Snapped 3820009 points\n",
      "[filter] Retained 85,479 of 85,785 features\n",
      "[clean] Retained 3,077 of 3,077 features\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_0.shp\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_0.shx\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_0.dbf\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_0.prj\n",
      "INFO:root:Filtering WDPA data based on Ramsar designation and in active protection...\n",
      "Allocating 16 GB of heap memory\n",
      "[i] Snapped 3620576 points\n",
      "[filter] Retained 85,513 of 85,784 features\n",
      "[clean] Retained 7,172 of 7,172 features\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_1.shp\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_1.shx\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_1.dbf\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_1.prj\n",
      "INFO:root:Filtering WDPA data based on Ramsar designation and in active protection...\n",
      "Allocating 16 GB of heap memory\n",
      "[i] Snapped 3073265 points\n",
      "[filter] Retained 85,140 of 85,785 features\n",
      "[clean] Retained 10,518 of 10,518 features\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_2.shp\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_2.shx\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_2.dbf\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_2.prj\n"
     ]
    }
   ],
   "source": [
    "## @usage: based on by single processing of the files.\n",
    "# for idx, inputPath in enumerate(paths):\n",
    "#     simplifyMapshaper(inputPath, \n",
    "#     f'{outFolder.parents[1]}/processed/wdpa_protected_areas_public_{idx}.shp', \n",
    "#     simplification=False, \n",
    "#     update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63a894f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 2115 entries, 0 to 2114\n",
      "Data columns (total 31 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   WDPAID      2115 non-null   int64   \n",
      " 1   WDPA_PID    2115 non-null   object  \n",
      " 2   PA_DEF      2115 non-null   object  \n",
      " 3   NAME        2115 non-null   object  \n",
      " 4   ORIG_NAME   2115 non-null   object  \n",
      " 5   DESIG       2115 non-null   object  \n",
      " 6   DESIG_ENG   2115 non-null   object  \n",
      " 7   DESIG_TYPE  2115 non-null   object  \n",
      " 8   IUCN_CAT    2115 non-null   object  \n",
      " 9   INT_CRIT    2115 non-null   object  \n",
      " 10  MARINE      2115 non-null   object  \n",
      " 11  REP_M_AREA  2115 non-null   float64 \n",
      " 12  GIS_M_AREA  2115 non-null   float64 \n",
      " 13  REP_AREA    2115 non-null   float64 \n",
      " 14  GIS_AREA    2115 non-null   float64 \n",
      " 15  NO_TAKE     2115 non-null   object  \n",
      " 16  NO_TK_AREA  2115 non-null   float64 \n",
      " 17  STATUS      2115 non-null   object  \n",
      " 18  STATUS_YR   2115 non-null   int64   \n",
      " 19  GOV_TYPE    2115 non-null   object  \n",
      " 20  OWN_TYPE    2115 non-null   object  \n",
      " 21  MANG_AUTH   2115 non-null   object  \n",
      " 22  MANG_PLAN   2115 non-null   object  \n",
      " 23  VERIF       2115 non-null   object  \n",
      " 24  METADATAID  2115 non-null   int64   \n",
      " 25  SUB_LOC     2115 non-null   object  \n",
      " 26  PARENT_ISO  2115 non-null   object  \n",
      " 27  ISO3        2115 non-null   object  \n",
      " 28  SUPP_INFO   2115 non-null   object  \n",
      " 29  CONS_OBJ    2115 non-null   object  \n",
      " 30  geometry    2115 non-null   geometry\n",
      "dtypes: float64(5), geometry(1), int64(3), object(22)\n",
      "memory usage: 512.4+ KB\n"
     ]
    }
   ],
   "source": [
    "wdpa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b7f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapRender(wdpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48158b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add a function to zip data and upload it to google cloud storage bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f40964",
   "metadata": {},
   "source": [
    "## Pipeline for wdpa data conversion into vector tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4da66189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbtilesGeneration(data_path: Path, output_path: Union[Path, None] = None,\n",
    " update: bool = False) -> Path:\n",
    "    \"\"\"\n",
    "    Simplify geometry of a GeoDataFrame using tippecanoe.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_path : Path - The path to the GeoDataFrame to simplify.\n",
    "    output_path : Path - The path to the output GeoDataFrame.\n",
    "    update : bool, optional - If True, the output GeoDataFrame will be overwritten.\n",
    "                            The default is False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Path - The path to the generated mbtiles file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        assert data_path.exists(), 'Data path does not exist.'\n",
    "        if not output_path:\n",
    "            output_path = data_path.with_suffix('.json')\n",
    "        \n",
    "        if update or not output_path.exists():\n",
    "            \n",
    "            if data_path.suffix != '.json':\n",
    "                CMD = f'mapshaper {data_path} -o format=geojson {data_path.with_suffix(\".json\")} force'\n",
    "                subprocess.run(CMD ,shell=True, check=True)\n",
    "                data_path = data_path.with_suffix('.json')\n",
    "\n",
    "            assert data_path.suffix == '.json', 'Data path must be a json file.'\n",
    "            \n",
    "            logging.info('Creating mbtiles file...')\n",
    "            \n",
    "            subprocess.run(\n",
    "                f\"tippecanoe -zg -f -P -o {output_path} --coalesce-densest-as-needed --extend-zooms-if-still-dropping {data_path}\",\n",
    "                shell=True, check=True\n",
    "                )\n",
    "        \n",
    "        return output_path\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b16326a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[o] Detected DBF text encoding: utf8\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.json\n",
      "INFO:root:Filtering WDPA data based on Ramsar designation and in active protection...\n",
      "For layer 0, using name \"wdpa_protected_areas_public\"\n",
      "/home/jovyan/work/datasets/processed/wdpa_protected_areas_public.json:1: Found unexpected character\n",
      "/home/jovyan/work/datasets/processed/wdpa_protected_areas_public.json:2: Found unexpected character\n",
      "/home/jovyan/work/datasets/processed/wdpa_protected_areas_public.json:2: Found unexpected character\n",
      "0 features, 10 bytes of geometry, 16 bytes of separate metadata, 0 bytes of string pool\n",
      "Did not read any valid geometries\n",
      "ERROR:root:Command 'tippecanoe -zg -f -P -o /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.json --coalesce-densest-as-needed --extend-zooms-if-still-dropping /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.json' returned non-zero exit status 1.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_file = Path(f'{outFolder.parents[1]}/processed/wdpa_protected_areas_public.shp')\n",
    "mbtilesGeneration(in_file, update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129481db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!npm install -g @mapbox/mbview  \n",
    "\n",
    "#!mbview $outputPath_mbtiles"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1bbcc470f389489f4ea214123e5e87adfd3a5448567a8d2709d702e835c91736"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
