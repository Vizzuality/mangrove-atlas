{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6c9a24",
   "metadata": {},
   "source": [
    "## Description of what we are going to do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883516a8",
   "metadata": {},
   "source": [
    "create_mangrove_wdpa_table.js file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60246a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import geopandas\n",
    "import zipfile\n",
    "import subprocess\n",
    "import logging\n",
    "import requests\n",
    "from typing import Union\n",
    "from ipyleaflet import Map, GeoData, basemaps, LayersControl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa4f76ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[?25h              \u001b[27m] \\ reify:flatbush: \u001b[32;40mhttp\u001b[0m \u001b[35mfetch\u001b[0m GET 200 https://registry.npmj\u001b[0m\u001b[K.n\u001b[0m\u001b[K\n",
      "added 65 packages, and audited 66 packages in 8s\n",
      "\n",
      "6 packages are looking for funding\n",
      "  run `npm fund` for details\n",
      "\n",
      "found \u001b[32m\u001b[1m0\u001b[22m\u001b[39m vulnerabilities\n"
     ]
    }
   ],
   "source": [
    "!npm install -g mapshaper@latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2ac5fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  FIXME: This will depends from where the notebook kernel is running so be carefull\n",
    "WORK_DIR =Path(os.getcwd())\n",
    "BASE_DIR = f'{WORK_DIR}/work/datasets/raw'\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# @TODO: Add expected data files source as an environment variable.\n",
    "assert BASE_DIR == '/home/jovyan/work/datasets/raw', f'{BASE_DIR} is not the correct directory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e5baf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_wdpaData(file_path: str, update: bool = False) -> Union[int, str]:\n",
    "    \"\"\"\n",
    "    Download a WDPA file to a path.\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str - The path to the file to download.\n",
    "    update : bool, optional - If True, the file will be downloaded again even if it already exists.\n",
    "                            The default is False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int - 0 if the file was downloaded successfully, 1 if the file download failed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if update or not os.path.exists(file_path):\n",
    "            logging.info('Downloading WDPA data...')\n",
    "            \n",
    "            url_info = requests.post('https://www.protectedplanet.net/downloads',\n",
    "                                data={\"domain\":\"general\",\n",
    "                                    \"format\":\"shp\",\n",
    "                                    \"token\":\"wdpa\",\n",
    "                                    \"id\":51216}\n",
    "                                )\n",
    "            \n",
    "            response = requests.get(url_info.json()['url'], stream=True)\n",
    "        \n",
    "            with open(file_path, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=128):\n",
    "                    f.write(chunk)\n",
    "        else:\n",
    "            logging.info('WDPA data already downloaded.')    \n",
    "        \n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "509c56c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wdpa_data(wdpa_zip_file: str, target_folder: str, format: str='.zip', update: bool = False) -> int:\n",
    "\n",
    "    \"\"\"\n",
    "    Extract WDPA data from a zip file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    wdpa_zip_file : str - The path to the zip file containing the WDPA data.\n",
    "    target_folder : str - The path to the folder to extract the WDPA data to.\n",
    "    format : str, optional - The format of the zip file. The default is '.zip'.\n",
    "    update : bool, optional - If True, the file will be extracted even if it already exists.\n",
    "                            The default is False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int - 0 if the file was extracted successfully, 1 if the file extraction failed.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        path = f'{BASE_DIR}/{target_folder}'\n",
    "\n",
    "        if update or not os.path.exists(path):\n",
    "            logging.info('Extracting WDPA data...')\n",
    "               \n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "\n",
    "            with zipfile.ZipFile(wdpa_zip_file, 'r') as zip_ref:\n",
    "                sublist = filter(lambda file: format in file, zip_ref.namelist())\n",
    "                zip_ref.extractall(path, members=sublist)\n",
    "        \n",
    "            for file in os.listdir(path):\n",
    "                if file.endswith(format):\n",
    "                    logging.info(file)\n",
    "                    \n",
    "                    inner_folder = f'{path}/{file[:-len(format)]}'\n",
    "                    \n",
    "                    with zipfile.ZipFile(f'{path}/{file}', 'r') as zip_ref:\n",
    "                        if not os.path.exists(inner_folder):\n",
    "                            os.mkdir(inner_folder)\n",
    "\n",
    "                        zip_ref.extractall(inner_folder)\n",
    "                    \n",
    "                    os.remove(f'{path}/{file}')\n",
    "        else:\n",
    "            logging.info('WDPA data already extracted.')\n",
    "            \n",
    "        return 0\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59f3b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wdpa_data(file_path: str) -> Union[int, geopandas.GeoDataFrame]:\n",
    "    \"\"\"\n",
    "    Load WDPA data from a csv file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str - The path to the csv file to load.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geopandas.GeoDataFrame - The loaded data.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return geopandas.read_file(file_path)\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c91f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplifyMapshaper(data_path: Path, output_path: Path, \n",
    "    simplification: bool, update: bool = False) -> Union[int, geopandas.GeoDataFrame]:\n",
    "    \"\"\"\n",
    "    Simplify geometry of a GeoDataFrame using mapshaper.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_path : Path - The path to the GeoDataFrame to simplify.\n",
    "    output_path : Path - The path to the output GeoDataFrame.\n",
    "    simplification : bool - If True, the data will be simplified.\n",
    "    update : bool, optional - If True, the output GeoDataFrame will be overwritten.\n",
    "                            The default is False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int - 0 if the data was simplified successfully, 1 if the data simplification failed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if update or not os.path.exists(output_path):\n",
    "            \n",
    "            logging.info('Filtering WDPA data based on Ramsar designation and in active protection...')\n",
    "            \n",
    "            subprocess.run(f\"mapshaper-xl 16gb -i {data_path} combine-files snap \\\n",
    "                -filter \\'STATUS!=\\\"Proposed\\\"\\' \\\n",
    "                -filter bbox=-180,-50,180,50 remove-empty \\\n",
    "                -clip source={BASE_DIR}/mangrove_coverage-v2.shp target=* \\\n",
    "                -merge-layers target=*\\\n",
    "                -clean rewind allow-overlaps \\\n",
    "                -o {output_path} format=shapefile force\", shell=True, check=True)\n",
    "        \n",
    "        if simplification:\n",
    "            logging.info('Simplifying WDPA data...')\n",
    "\n",
    "            subprocess.run(f\"mapshaper-xl 16gb -i {output_path} \\\n",
    "                -simplify 50% visvalingam keep-shapes planar \\\n",
    "                -filter-islands min-vertices=3 min-area=10000m2 remove-empty \\\n",
    "                -filter-slivers min-area=10000m2 remove-empty \\\n",
    "                -clean rewind \\\n",
    "                -o {output_path} format=shapefile force\", shell=True, check=True)\n",
    "        \n",
    "        return load_wdpa_data(output_path)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcb6ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapRender(data: geopandas.GeoDataFrame) -> Map:\n",
    "    \"\"\"\n",
    "    Render a map with the given data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : geopandas.GeoDataFrame - The data to render.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Map - The rendered map.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        m = Map(center=(52.3,8.0), \n",
    "            zoom = 3, \n",
    "            basemap= basemaps.Esri.WorldTopoMap,\n",
    "            layers_control=True,\n",
    "            controls=[\n",
    "                LayersControl()\n",
    "            ])\n",
    "        geo_data = GeoData(\n",
    "                    geo_dataframe=data,\n",
    "                    style={\n",
    "                        'color': '#ff0000',\n",
    "                        'fillOpacity': 0.5\n",
    "                    },\n",
    "                    name='WDPA',\n",
    "                )\n",
    "        m.add_layer(geo_data)\n",
    "\n",
    "        \n",
    "        return m\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7b1f43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:WDPA data already downloaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_wdpaData(f'{BASE_DIR}/wdpa_protected_areas_public.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2229eb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:WDPA data already extracted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_wdpa_data(f'{BASE_DIR}/wdpa_protected_areas_public.zip', 'wdpa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa6b7985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/datasets/processed/wdpa_protected_areas_public.shp\n"
     ]
    }
   ],
   "source": [
    "outFolder= Path(f'{BASE_DIR}/wdpa')\n",
    "paths =[]\n",
    "for root, dirs, files in os.walk(outFolder):\n",
    "    for file in files:\n",
    "        if file.endswith(\"-polygons.shp\"):\n",
    "            paths.append(os.path.join(root, file))\n",
    "\n",
    "path = ' '.join(paths)\n",
    "\n",
    "outputPath = f'{outFolder.parents[1]}/processed/wdpa_protected_areas_public.shp'\n",
    "print(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e14d4bc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering WDPA data based on Ramsar designation and in active protection...\n",
      "Allocating 16 GB of heap memory\n",
      "[i] Snapped 19910585 points\n",
      "[filter] Retained 85,479 of 85,785 features\n",
      "[filter] Retained 85,513 of 85,784 features\n",
      "[filter] Retained 85,140 of 85,785 features\n",
      "[filter] Retained 48,097 of 85,479 features\n",
      "[filter] Retained 57,392 of 85,513 features\n",
      "[filter] Retained 43,671 of 85,140 features\n",
      "[clean] Retained 20,767 of 20,767 features\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.shp\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.shx\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.dbf\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public.prj\n"
     ]
    }
   ],
   "source": [
    "wdpa = simplifyMapshaper(path, outputPath, simplification=False, update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd29bc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filtering WDPA data based on Ramsar designation and in active protection...\n",
      "Allocating 16 GB of heap memory\n",
      "[i] Snapped 3820009 points\n",
      "[filter] Retained 85,479 of 85,785 features\n",
      "[clean] Retained 3,077 of 3,077 features\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_0.shp\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_0.shx\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_0.dbf\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_0.prj\n",
      "INFO:root:Filtering WDPA data based on Ramsar designation and in active protection...\n",
      "Allocating 16 GB of heap memory\n",
      "[i] Snapped 3620576 points\n",
      "[filter] Retained 85,513 of 85,784 features\n",
      "[clean] Retained 7,172 of 7,172 features\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_1.shp\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_1.shx\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_1.dbf\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_1.prj\n",
      "INFO:root:Filtering WDPA data based on Ramsar designation and in active protection...\n",
      "Allocating 16 GB of heap memory\n",
      "[i] Snapped 3073265 points\n",
      "[filter] Retained 85,140 of 85,785 features\n",
      "[clean] Retained 10,518 of 10,518 features\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_2.shp\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_2.shx\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_2.dbf\n",
      "[o] Wrote /home/jovyan/work/datasets/processed/wdpa_protected_areas_public_2.prj\n"
     ]
    }
   ],
   "source": [
    "## @usage: based on by single processing of the files.\n",
    "# for idx, inputPath in enumerate(paths):\n",
    "#     simplifyMapshaper(inputPath, \n",
    "#     f'{outFolder.parents[1]}/processed/wdpa_protected_areas_public_{idx}.shp', \n",
    "#     simplification=False, \n",
    "#     update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63a894f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 2115 entries, 0 to 2114\n",
      "Data columns (total 31 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   WDPAID      2115 non-null   int64   \n",
      " 1   WDPA_PID    2115 non-null   object  \n",
      " 2   PA_DEF      2115 non-null   object  \n",
      " 3   NAME        2115 non-null   object  \n",
      " 4   ORIG_NAME   2115 non-null   object  \n",
      " 5   DESIG       2115 non-null   object  \n",
      " 6   DESIG_ENG   2115 non-null   object  \n",
      " 7   DESIG_TYPE  2115 non-null   object  \n",
      " 8   IUCN_CAT    2115 non-null   object  \n",
      " 9   INT_CRIT    2115 non-null   object  \n",
      " 10  MARINE      2115 non-null   object  \n",
      " 11  REP_M_AREA  2115 non-null   float64 \n",
      " 12  GIS_M_AREA  2115 non-null   float64 \n",
      " 13  REP_AREA    2115 non-null   float64 \n",
      " 14  GIS_AREA    2115 non-null   float64 \n",
      " 15  NO_TAKE     2115 non-null   object  \n",
      " 16  NO_TK_AREA  2115 non-null   float64 \n",
      " 17  STATUS      2115 non-null   object  \n",
      " 18  STATUS_YR   2115 non-null   int64   \n",
      " 19  GOV_TYPE    2115 non-null   object  \n",
      " 20  OWN_TYPE    2115 non-null   object  \n",
      " 21  MANG_AUTH   2115 non-null   object  \n",
      " 22  MANG_PLAN   2115 non-null   object  \n",
      " 23  VERIF       2115 non-null   object  \n",
      " 24  METADATAID  2115 non-null   int64   \n",
      " 25  SUB_LOC     2115 non-null   object  \n",
      " 26  PARENT_ISO  2115 non-null   object  \n",
      " 27  ISO3        2115 non-null   object  \n",
      " 28  SUPP_INFO   2115 non-null   object  \n",
      " 29  CONS_OBJ    2115 non-null   object  \n",
      " 30  geometry    2115 non-null   geometry\n",
      "dtypes: float64(5), geometry(1), int64(3), object(22)\n",
      "memory usage: 512.4+ KB\n"
     ]
    }
   ],
   "source": [
    "wdpa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b7f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapRender(wdpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48158b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add a function to zip data and upload it to google cloud storage bucket"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
