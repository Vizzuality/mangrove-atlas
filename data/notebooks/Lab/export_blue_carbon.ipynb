{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Blue Carbon tiffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### **Step 1:** Take Blue carbon Asset from GEE and export to the cloud storage as tiffs\n",
    "* #### **Step 2:** Take exported tiffs and unify into one single file and reupload to GCS\n",
    "\n",
    "Requires autentication into Google earth Engine and into Google Cloud Storage. This notebook uses credentials stored in a file `service_account.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Export Asset (GEE) to tiff (GCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = ee.Geometry.Polygon([-180, 40, 0,40,180, 40,180,-40,0,-40,-180,-40])\n",
    "coll = ee.ImageCollection(\"projects/global-mangrove-watch/mangrove-properties/mangrove_total_co2e_1996--2016\").select('total_co2e')\n",
    "collectionList = coll.toList(coll.size())\n",
    "collectionSize = collectionList.size().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i= 0\n",
    "img = ee.Image(collectionList.get(i))\n",
    "img_name = ee.String(img.get(\"system:id\")).split(\"/\").get(-1).getInfo()\n",
    "year = img_name[-4:]\n",
    "\n",
    "params = {\n",
    "'image':img,\n",
    "'description':'toc_'+year,\n",
    "'bucket':'mangrove_atlas',\n",
    "'fileNamePrefix':'ee_export_tiffs/total_organic_carbon/toc_'+year+'/toc_'+year, \n",
    "'fileFormat':'GeoTIFF',\n",
    "'region': region.getInfo()['coordinates'], \n",
    "'skipEmptyTiles': False,\n",
    "'maxPixels': 1e12,\n",
    "'scale':30\n",
    "}\n",
    "\n",
    "task = ee.batch.Export.image.toCloudStorage(**params)\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,collectionSize):\n",
    "    img = ee.Image(collectionList.get(i))\n",
    "    img_name = ee.String(img.get(\"system:id\")).split(\"/\").get(-1).getInfo()\n",
    "    year = img_name[-4:]\n",
    "\n",
    "    params = {\n",
    "    'image':img,\n",
    "    'description':'toc_'+year,\n",
    "    'bucket':'mangrove_atlas',\n",
    "    'fileNamePrefix':'ee_export_tiffs/total_organic_carbon/toc_'+year+'/toc_'+year, \n",
    "    'fileFormat':'GeoTIFF',\n",
    "    'region': region.getInfo()['coordinates'], \n",
    "    'skipEmptyTiles': False,\n",
    "    'maxPixels': 1e12,\n",
    "    'scale': 30,\n",
    "    }\n",
    "\n",
    "    task = ee.batch.Export.image.toCloudStorage(**params)\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check task status\n",
    "!earthengine task list --status RUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!earthengine task list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Download tiffs (from GCS), Unify into 1 file (gdal) and upload (back to GCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_gcs_credentials = '../../data/service_account.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name, path_to_gcs_credentials):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # source_file_name = \"local/path/to/file\"\n",
    "    # destination_blob_name = \"storage-object-name\"\n",
    "\n",
    "    storage_client = storage.Client.from_service_account_json(path_to_gcs_credentials)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\n",
    "        \"File {} uploaded to {}.\".format(\n",
    "            source_file_name, destination_blob_name\n",
    "        )\n",
    "    )\n",
    "#https://stackoverflow.com/questions/49748910/python-download-entire-directory-from-google-cloud-storage    \n",
    "def download_blob(bucket_name, prefix, dest_folder,path_to_gcs_credentials):\n",
    "    \"\"\"Downloads a file to the bucket.\"\"\"\n",
    "     # bucket_name = 'your-bucket-name'\n",
    "     # prefix = 'your-bucket-directory/' or 'your-bucket-directory/and-file-name'\n",
    "     # dest_folder = 'your-local-directory/'\n",
    "\n",
    "    storage_client = storage.Client.from_service_account_json(path_to_gcs_credentials)\n",
    "\n",
    "    # Retrieve all blobs with a prefix matching the folder\n",
    "    bucket=storage_client.get_bucket(bucket_name)\n",
    "    print(bucket)\n",
    "    blobs=list(bucket.list_blobs(prefix=folder))\n",
    "\n",
    "    for blob in blobs:\n",
    "        try: \n",
    "            if(not blob.name.endswith(\"/\")):\n",
    "                file_split = blob.name.split(\"/\")\n",
    "                blob.download_to_filename(f\"{dest_folder}{file_split[-1]}\")\n",
    "        except OSError as err:\n",
    "            print(\"OS error: {0}\".format(err))\n",
    "            print(file_split[-1])\n",
    "            continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=1996\n",
    "bucket_name = 'mangrove_atlas'\n",
    "\n",
    "## example for a set of files with the prefix toc_19960000023296\n",
    "## to export complete folder, stop path at the previous folder level\n",
    "prefix=f'ee_export_tiffs/total_organic_carbon/toc_{y}/toc_19960000023296'\n",
    "dest_folder_tiffs = '../../data/toc_temporary/\n",
    "dest_folder_mosaic = \"../../data/gmw_blue_carbon/\"\n",
    "os.makedirs(dest_folder_tiffs, exist_ok=True)\n",
    "os.makedirs(dest_folder_mosaic, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#for y in [1996, 2007, 2008, 2009, 2010, 2015, 2016, 2017, 2018, 2019, 2020]:\n",
    "for y in [1996]: ## test one year\n",
    "    #prefix=f'ee_export_tiffs/total_organic_carbon/toc_{y}/toc_19960000023296'\n",
    "    #download_blob(bucket_name,prefix,dest_folder_tiffs)\n",
    "    #print(\"\\nBuilding VRT\\n\")\n",
    "    #!gdalbuildvrt {dest_folder_mosaic}/gmw_toc_{y}.vrt {dest_folder_tiffs}/*.tif\n",
    "    print(\"\\nBuilding GeoTIFF\\n\")\n",
    "    !gdal_translate -co \"BLOCKXSIZE=512\" -co \"BLOCKYSIZE=512\" -co \"TILED=YES\" -co \"BIGTIFF=YES\" -co \"COMPRESS=DEFLATE\" {dest_folder_mosaic}/gmw_toc_{y}.vrt {dest_folder_mosaic}/gmw_toc_{y}.tif\n",
    "    print(\"\\nCopying files to GCS\\n\")\n",
    "    upload_blob('mangrove_atlas', f'{dest_folder_mosaic}/gmw_toc_{y}.tif', f'ee_export_tiffs/total_organic_carbon/v2/toc_{y}.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note (Feb 9th 2022)\n",
    "This test was made with a subset of files, this must be done with the complete folder to check that the final file has the global extent. The download of tiffs and its processing takes an important amount of disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
