{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e692a33e",
   "metadata": {},
   "source": [
    "## Export Blue Carbon tiffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafa69ee",
   "metadata": {},
   "source": [
    "* #### **Step 1:** Take Blue carbon Asset from GEE and export to the cloud storage as tiffs\n",
    "* #### **Step 2:** Take exported tiffs and unify into one single file and reupload to GCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5921436a",
   "metadata": {},
   "source": [
    "### Step 1: Export Asset (GEE) to tiff (GCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "613c79e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cde7a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=_VI1_AVLTflhNNtpzJRY2XXZ5cJ4PYb_cM5GYD8525w&code_challenge_method=S256>https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=_VI1_AVLTflhNNtpzJRY2XXZ5cJ4PYb_cM5GYD8525w&code_challenge_method=S256</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you\n",
       "        should paste in the box below</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter verification code:  4/1AX4XfWiVYOUggDLJ-ct3ozWTee8nnp_gAmGF3ic0x0G4lwKNFZf8PoXUqgg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea04cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce819b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = ee.Geometry.Polygon([-180, 40, 0,40,180, 40,180,-40,0,-40,-180,-40])\n",
    "coll = ee.ImageCollection(\"projects/global-mangrove-watch/mangrove-properties/mangrove_total_co2e_1996--2016\").select('total_co2e')\n",
    "collectionList = coll.toList(coll.size())\n",
    "collectionSize = collectionList.size().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cef39180",
   "metadata": {},
   "outputs": [],
   "source": [
    "i= 0\n",
    "img = ee.Image(collectionList.get(i))\n",
    "img_name = ee.String(img.get(\"system:id\")).split(\"/\").get(-1).getInfo()\n",
    "year = img_name[-4:]\n",
    "\n",
    "params = {\n",
    "'image':img,\n",
    "'description':'toc_'+year,\n",
    "'bucket':'mangrove_atlas',\n",
    "'fileNamePrefix':'ee_export_tiffs/total_organic_carbon/toc_'+year+'/toc_'+year, \n",
    "'fileFormat':'GeoTIFF',\n",
    "'region': region.getInfo()['coordinates'], \n",
    "'skipEmptyTiles': False,\n",
    "'maxPixels': 1e12,\n",
    "'scale':30\n",
    "}\n",
    "\n",
    "task = ee.batch.Export.image.toCloudStorage(**params)\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb9de3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,collectionSize):\n",
    "    img = ee.Image(collectionList.get(i))\n",
    "    img_name = ee.String(img.get(\"system:id\")).split(\"/\").get(-1).getInfo()\n",
    "    year = img_name[-4:]\n",
    "\n",
    "    params = {\n",
    "    'image':img,\n",
    "    'description':'toc_'+year,\n",
    "    'bucket':'mangrove_atlas',\n",
    "    'fileNamePrefix':'ee_export_tiffs/total_organic_carbon/toc_'+year+'/toc_'+year, \n",
    "    'fileFormat':'GeoTIFF',\n",
    "    'region': region.getInfo()['coordinates'], \n",
    "    'skipEmptyTiles': False,\n",
    "    'maxPixels': 1e12,\n",
    "    'scale': 30,\n",
    "    }\n",
    "\n",
    "    task = ee.batch.Export.image.toCloudStorage(**params)\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e73e89ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check task status\n",
    "!earthengine task list --status RUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94268b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GS5LHZ7DHQIZIGWKWITEGJPY  Export.image  toc_2016  COMPLETED  ---\n",
      "ZSRTQT4UBTJT4JQK65KRQWB2  Export.image  toc_2015  COMPLETED  ---\n",
      "LPNGZWJSCK36JZAFY342U52L  Export.image  toc_2010  COMPLETED  ---\n",
      "7TXT6XFST545LSE4NMM6MPJ2  Export.image  toc_2009  COMPLETED  ---\n",
      "NMDRUGZWALRJCJSKM3SAGTJ5  Export.image  toc_2008  COMPLETED  ---\n",
      "OW67FABLD4OORUTLQ2UBIRMX  Export.image  toc_2007  COMPLETED  ---\n",
      "RATJ2X5XOBXHFKWN2ZOTPBOP  Export.image  toc_2000  COMPLETED  ---\n",
      "NFRDZAQY75G4HNBM73O3TSTW  Export.image  toc_1996  COMPLETED  ---\n",
      "VE4FBE247HDC56TBMVZHHRJZ  Export.image  toc_1996  FAILED     Unable to write to bucket magrove_atlas (not found).\n",
      "2WWOJMVYLIQFV6G7OYQ5TY5M  Export.image  toc_1996  FAILED     Export too large: specified 1036802880000 pixels (max: 100000000). Specify higher maxPixels value if you intend to export a large area.\n",
      "KF7ISWKSLQM7QANWM2KE4FNN  Export.image  toc_2016  FAILED     Internal error.\n",
      "FL4NEFRGO3KFYVRG45DBBW2Y  Export.image  toc_2015  FAILED     Execution failed; out of memory.\n",
      "6OBTPMJVNIKUY3OEX2SNUEW4  Export.image  toc_2010  FAILED     Internal error.\n",
      "5XVUYEJVRHDS36QJO7KCDTRD  Export.image  toc_2009  FAILED     Internal error.\n",
      "DP6J7XH5ZECTBWDGHMVGY7DU  Export.image  toc_2008  FAILED     Internal error.\n",
      "EFN6YM5AOM7MSNOYVJFBZO6V  Export.image  toc_2007  FAILED     Internal error.\n",
      "L3YACVDFEAFWWVP2RRD4KN5H  Export.image  toc_2000  FAILED     Internal error.\n",
      "T5WNHDS3WZPX5VPEW5723Y4S  Export.image  toc_1996  FAILED     Internal error.\n",
      "FT2MLLBM2PHBHAOVFZSUTNSQ  Export.image  toc_1996  FAILED     Export too large: specified 1036802880000 pixels (max: 100000000). Specify higher maxPixels value if you intend to export a large area.\n",
      "G2J7LJIXFNMT6IEGXNIEHIBA  Export.image  toc_1996  FAILED     Export too large: specified 1036802880000 pixels (max: 100000000). Specify higher maxPixels value if you intend to export a large area.\n",
      "PED3QJPTUBUNBGLII7SMD4UA  Export.image  toc_1996  FAILED     Export too large: specified 1036802880000 pixels (max: 100000000). Specify higher maxPixels value if you intend to export a large area.\n",
      "NQQW7KJ57HS6HLTOWXMJFIMS  Export.image  toc_1996  FAILED     Export too large: specified 1036802880000 pixels (max: 100000000). Specify higher maxPixels value if you intend to export a large area.\n",
      "IZEWPK3P5SENAW5GZ7DK54GH  Export.image  toc_1996  FAILED     Export too large: specified 1036802880000 pixels (max: 100000000). Specify higher maxPixels value if you intend to export a large area.\n"
     ]
    }
   ],
   "source": [
    "!earthengine task list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6401f461",
   "metadata": {},
   "source": [
    "### Step 2: Download tiffs (GCS), Unify into 1 file (gdal) and upload (GCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309c7437",
   "metadata": {},
   "source": [
    "#### Download tiffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a7702c",
   "metadata": {},
   "source": [
    "## Unify and upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9e425cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # source_file_name = \"local/path/to/file\"\n",
    "    # destination_blob_name = \"storage-object-name\"\n",
    "\n",
    "    storage_client = storage.Client.from_service_account_json('../../datasets/service_account.json')\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\n",
    "        \"File {} uploaded to {}.\".format(\n",
    "            source_file_name, destination_blob_name\n",
    "        )\n",
    "    )\n",
    "#https://stackoverflow.com/questions/49748910/python-download-entire-directory-from-google-cloud-storage    \n",
    "def download_blob(bucket_name, prefix, dl_dir):\n",
    "    \"\"\"Downloads a file to the bucket.\"\"\"\n",
    "     # bucket_name = 'your-bucket-name'\n",
    "     # prefix = 'your-bucket-directory/'\n",
    "     # dl_dir = 'your-local-directory/'\n",
    "\n",
    "    storage_client = storage.Client.from_service_account_json('../../datasets/service_account.json')\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=prefix)  # Get list of files\n",
    "\n",
    "    for blob in blobs:\n",
    "        if blob.name.endswith(\"/\"):\n",
    "                continue\n",
    "        file_split = blob.name.split(\"/\")\n",
    "        directory = \"/\".join(file_split[0:-1])\n",
    "        Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "        blob.download_to_filename(blob.name)\n",
    "\n",
    "    print(\n",
    "        \"Folder {} downloaded to {}.\".format(\n",
    "            prefix, dl_dir\n",
    "        )\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "410a369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=1996\n",
    "bucket_name = 'mangrove_atlas'\n",
    "prefix = f'toc_{y}/'\n",
    "storage_client = storage.Client.from_service_account_json('../../datasets/service_account.json')\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blobs = bucket.list_blobs(prefix=prefix)  # Get list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49ebc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_blob('mangrove_atlas',f'ee_export_tiffs/total_organic_carbon/toc_{y}/toc_{y}',path_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4fe97a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1996\n",
    "bucket_name = 'mangrove_atlas'\n",
    "#folder='/projects/bigquery/download/shakespeare/'\n",
    "folder=f'ee_export_tiffs/total_organic_carbon/toc_{y}/'\n",
    "delimiter='/'\n",
    "file = f'/toc_{y}'\n",
    "\n",
    "# Retrieve all blobs with a prefix matching the file.\n",
    "bucket=storage_client.get_bucket(bucket_name)\n",
    "# List blobs iterate in folder \n",
    "blobs=bucket.list_blobs(prefix=file, delimiter=delimiter) # Excluding folder inside bucket\n",
    "for blob in blobs:\n",
    "    print(blob.name)\n",
    "    #destination_uri = '{}/{}'.format(folder, blob.name) \n",
    "    #blob.download_to_filename(destination_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6153e389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Bucket: mangrove_atlas>\n"
     ]
    }
   ],
   "source": [
    "# [download multiple files]\n",
    "y=1996\n",
    "bucket_name = 'mangrove_atlas'\n",
    "# The \"folder\" where the files you want to download are\n",
    "folder=f'ee_export_tiffs/total_organic_carbon/toc_{y}/'\n",
    "\n",
    "\n",
    "# Retrieve all blobs with a prefix matching the folder\n",
    "bucket=storage_client.get_bucket(bucket_name)\n",
    "print(bucket)\n",
    "blobs=list(bucket.list_blobs(prefix=folder))\n",
    "\n",
    "for blob in blobs:\n",
    "    try: \n",
    "        if(not blob.name.endswith(\"/\")):\n",
    "            file_split = blob.name.split(\"/\")\n",
    "            blob.download_to_filename(f\"../../datasets/toc_temporary/{file_split[-1]}\")\n",
    "    except OSError as err:\n",
    "        print(\"OS error: {0}\".format(err))\n",
    "        print(file_split[-1])\n",
    "        continue\n",
    "\n",
    "# [End download to multiple files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd38e1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ee_export_tiffs/total_organic_carbon/toc_1996'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_split = blob.name.split(\"/\")\n",
    "directory = \"/\".join(file_split[0:-1])\n",
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fbbddf04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toc_19960000000000-0000000000.tif'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_split[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37f7f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directories\n",
    "import os\n",
    "path_in = \"../../datasets/toc_temporary/\"\n",
    "path_out =\"../../datasets/gmw_blue_carbon/\"\n",
    "os.makedirs(path_out, exist_ok=True)\n",
    "os.makedirs(path_in, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64ca36cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../datasets/toc_temporary/ee_export_tiffs/total_organic_carbon/toc_1996/toc_19960000000000-0000000000.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_67/1477355727.py\u001b[0m in \u001b[0;36mdownload_blob\u001b[0;34m(bucket_name, prefix, dl_dir)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mblob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_to_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     print(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/google/cloud/storage/blob.py\u001b[0m in \u001b[0;36mdownload_to_filename\u001b[0;34m(self, filename, client, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_require_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m                 client.download_blob_to_file(\n\u001b[1;32m   1284\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../datasets/toc_temporary/ee_export_tiffs/total_organic_carbon/toc_1996/toc_19960000000000-0000000000.tif'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#for y in [1996, 2007, 2008, 2009, 2010, 2015, 2016, 2017, 2018, 2019, 2020]:\n",
    "for y in [1996]:\n",
    "    download_blob('mangrove_atlas',f'ee_export_tiffs/total_organic_carbon/toc_{y}/toc_{y}',path_in)\n",
    "    print(\"\\nBuilding VRT\\n\")\n",
    "    !gdalbuildvrt {path_out}/gmw_toc_{y}.vrt {path_in}/*.tif\n",
    "    print(\"\\nBuilding GeoTIFF\\n\")\n",
    "    !gdal_translate -co \"BLOCKXSIZE=512\" -co \"BLOCKYSIZE=512\" -co \"TILED=YES\" -co \"BIGTIFF=YES\" -co \"COMPRESS=DEFLATE\" {path_out}/gmw_toc_{y}.vrt {path_out}/gmw_toc_{y}.tif\n",
    "    print(\"\\nCopying files to GCS\\n\")\n",
    "    upload_blob('mangrove_atlas', f'{path_out}/gmw_toc_{y}.tif', f'ee_export_tiffs/total_organic_carbon/v2/toc_{y}.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ee595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
